{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dabj4NLXsBFm"
      },
      "source": [
        "# Audio Injection with Magenta RT!\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/magenta/magenta-realtime/blob/main/notebooks/Magenta_RT_Audio_Injection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This notebook shows how live input audio can be â€œinjectedâ€ into Magenta RTâ€™s context to steer its generation. The model may repeat your input, or may *transform* it into something else! Try different prompts for different results.\n",
        "\n",
        "### Tips for live mic input:\n",
        "\n",
        "1. Use **wired** headphones! ğŸ§ã€°ã€°ğŸ’»\n",
        "1. **Rerun** â±ï¸ `Measure latency` after any system audio change, like opening or closing an app.\n",
        "1. Start by inputting something with a **clear rhythm**. You can tap along with the metronome, or count 1-2-3-4, or try other sounds!\n",
        "\n",
        "### Known issues\n",
        "\n",
        "- The model may drift off of the set tempo.\n",
        "- Latency measurement may not work properly when routing audio from another application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Oq0xSB8scXP"
      },
      "source": [
        "# Step 1: ğŸ˜´ One-time setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mwRM5Mvef5Oq",
        "outputId": "c0ba7295-ce99-4232-e492-828096a94f7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'magenta-realtime'...\n",
            "remote: Enumerating objects: 185, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 185 (delta 61), reused 75 (delta 45), pack-reused 70 (from 1)\u001b[K\n",
            "Receiving objects: 100% (185/185), 1.18 MiB | 7.89 MiB/s, done.\n",
            "Resolving deltas: 100% (73/73), done.\n",
            "Obtaining file:///content/magenta-realtime\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flaxformer@ git+https://github.com/google/flaxformer@399ea3a (from magenta_rt==0.2.0)\n",
            "  Cloning https://github.com/google/flaxformer (to revision 399ea3a) to /tmp/pip-install-9x5viual/flaxformer_847133de002341c18bc0ec7690818c0a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google/flaxformer /tmp/pip-install-9x5viual/flaxformer_847133de002341c18bc0ec7690818c0a\n",
            "\u001b[33m  WARNING: Did not find branch or tag '399ea3a', assuming revision or ref.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running command git checkout -q 399ea3a\n",
            "  Resolved https://github.com/google/flaxformer to commit 399ea3a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting t5x@ git+https://github.com/google-research/t5x.git@92c5b46 (from magenta_rt==0.2.0)\n",
            "  Cloning https://github.com/google-research/t5x.git (to revision 92c5b46) to /tmp/pip-install-9x5viual/t5x_b1c4414e4a6a4ea39c2f43618c038338\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google-research/t5x.git /tmp/pip-install-9x5viual/t5x_b1c4414e4a6a4ea39c2f43618c038338\n",
            "\u001b[33m  WARNING: Did not find branch or tag '92c5b46', assuming revision or ref.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running command git checkout -q 92c5b46\n",
            "  Resolved https://github.com/google-research/t5x.git to commit 92c5b46\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from magenta_rt==0.2.0) (1.4.0)\n",
            "Requirement already satisfied: chex in /usr/local/lib/python3.11/dist-packages (from magenta_rt==0.2.0) (0.1.90)\n",
            "Collecting clu (from magenta_rt==0.2.0)\n",
            "  Downloading clu-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.11/dist-packages (from magenta_rt==0.2.0) (0.10.6)\n",
            "Collecting gin-config (from magenta_rt==0.2.0)\n",
            "  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from magenta_rt==0.2.0) (2.19.0)\n",
            "Collecting jax==0.6.2 (from magenta_rt==0.2.0)\n",
            "  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib==0.6.2 (from magenta_rt==0.2.0)\n",
            "  Downloading jaxlib-0.6.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from magenta_rt==0.2.0) (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from magenta_rt==0.2.0) (2.0.2)\n",
            "Collecting resampy (from magenta_rt==0.2.0)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from magenta_rt==0.2.0) (2.32.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from magenta_rt==0.2.0) (0.2.0)\n",
            "Collecting seqio (from magenta_rt==0.2.0)\n",
            "  Downloading seqio-0.0.19-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from magenta_rt==0.2.0) (0.13.1)\n",
            "Collecting tensorflow-text-nightly (from magenta_rt==0.2.0)\n",
            "  Downloading tensorflow_text_nightly-2.20.0.dev20250619-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting tf-nightly (from magenta_rt==0.2.0)\n",
            "  Downloading tf_nightly-2.21.0.dev20250729-cp311-cp311-manylinux_2_27_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting tf-hub-nightly (from magenta_rt==0.2.0)\n",
            "  Downloading tf_hub_nightly-0.17.0.dev202506230306-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tf2jax (from magenta_rt==0.2.0)\n",
            "  Downloading tf2jax-0.3.7-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from magenta_rt==0.2.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from magenta_rt==0.2.0) (4.14.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from jax==0.6.2->magenta_rt==0.2.0) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax==0.6.2->magenta_rt==0.2.0) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.11/dist-packages (from jax==0.6.2->magenta_rt==0.2.0) (1.16.1)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex->magenta_rt==0.2.0) (1.0.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.11/dist-packages (from clu->magenta_rt==0.2.0) (1.13.0)\n",
            "Collecting ml-collections (from clu->magenta_rt==0.2.0)\n",
            "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clu->magenta_rt==0.2.0) (25.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from clu->magenta_rt==0.2.0) (1.17.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from flax->magenta_rt==0.2.0) (1.1.1)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from flax->magenta_rt==0.2.0) (0.2.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from flax->magenta_rt==0.2.0) (0.11.20)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.11/dist-packages (from flax->magenta_rt==0.2.0) (0.1.76)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.11/dist-packages (from flax->magenta_rt==0.2.0) (14.1.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from flax->magenta_rt==0.2.0) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax->magenta_rt==0.2.0) (0.1.9)\n",
            "Collecting aqtp>=0.1.0 (from flaxformer@ git+https://github.com/google/flaxformer@399ea3a->magenta_rt==0.2.0)\n",
            "  Downloading aqtp-0.9.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->magenta_rt==0.2.0) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->magenta_rt==0.2.0) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->magenta_rt==0.2.0) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->magenta_rt==0.2.0) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->magenta_rt==0.2.0) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->magenta_rt==0.2.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->magenta_rt==0.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->magenta_rt==0.2.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->magenta_rt==0.2.0) (2025.8.3)\n",
            "Collecting libtpu==0.0.17.* (from jax[tpu]; extra == \"tpu\"->magenta_rt==0.2.0)\n",
            "  Downloading libtpu-0.0.17-py3-none-manylinux_2_31_x86_64.whl.metadata (500 bytes)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->magenta_rt==0.2.0) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->magenta_rt==0.2.0) (0.61.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->magenta_rt==0.2.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->magenta_rt==0.2.0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->magenta_rt==0.2.0) (5.2.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->magenta_rt==0.2.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->magenta_rt==0.2.0) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->magenta_rt==0.2.0) (0.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->magenta_rt==0.2.0) (1.17.1)\n",
            "Collecting editdistance (from seqio->magenta_rt==0.2.0)\n",
            "  Downloading editdistance-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting pyglove (from seqio->magenta_rt==0.2.0)\n",
            "  Downloading pyglove-0.4.5-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting tensorflow-text (from seqio->magenta_rt==0.2.0)\n",
            "  Downloading tensorflow_text-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting tfds-nightly==4.9.2.dev202308090034 (from seqio->magenta_rt==0.2.0)\n",
            "  Downloading tfds_nightly-4.9.2.dev202308090034-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting protobuf<=3.20.3 (from seqio->magenta_rt==0.2.0)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.11/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0) (0.7.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0) (8.2.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0) (0.1.9)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0) (1.17.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0) (3.1.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0) (0.10.2)\n",
            "Collecting airio@ git+https://github.com/google/airio#egg=airio (from t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Cloning https://github.com/google/airio to /tmp/pip-install-9x5viual/airio_47361785d9d34226bb7d1fb361368435\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google/airio /tmp/pip-install-9x5viual/airio_47361785d9d34226bb7d1fb361368435\n",
            "  Resolved https://github.com/google/airio to commit 7feb9ddc2083dd219ffa947901cf61de9132a28a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clu@ git+https://github.com/google/CommonLoopUtils#egg=clu (from t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Cloning https://github.com/google/CommonLoopUtils to /tmp/pip-install-9x5viual/clu_28c91d4e78814e8f8fa1443bee45a5e3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google/CommonLoopUtils /tmp/pip-install-9x5viual/clu_28c91d4e78814e8f8fa1443bee45a5e3\n",
            "  Resolved https://github.com/google/CommonLoopUtils to commit 949e50380a67c934f1d10bcf241cb0c56d369289\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flax@ git+https://github.com/google/flax#egg=flax (from t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Cloning https://github.com/google/flax to /tmp/pip-install-9x5viual/flax_ede25721593d4a2eaed29ca83d5a3407\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google/flax /tmp/pip-install-9x5viual/flax_ede25721593d4a2eaed29ca83d5a3407\n",
            "  Resolved https://github.com/google/flax to commit 38cd908390b188e256b75c906b02ba0cd8795cf1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jestimator@ git+https://github.com/google-research/jestimator#egg=jestimator (from t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Cloning https://github.com/google-research/jestimator to /tmp/pip-install-9x5viual/jestimator_4e7eeaf49b734bd2b20891575b456e90\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google-research/jestimator /tmp/pip-install-9x5viual/jestimator_4e7eeaf49b734bd2b20891575b456e90\n",
            "  Resolved https://github.com/google-research/jestimator to commit 326824a477feef6d92e6f44175000907a72899ca\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting optax@ git+https://github.com/deepmind/optax#egg=optax (from t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Cloning https://github.com/deepmind/optax to /tmp/pip-install-9x5viual/optax_ae54005669f14b6d8343f34d0216146f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepmind/optax /tmp/pip-install-9x5viual/optax_ae54005669f14b6d8343f34d0216146f\n",
            "  Resolved https://github.com/deepmind/optax to commit 74c68567280cc9d68bde0bdca41258808385295c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting seqio@ git+https://github.com/google/seqio#egg=seqio (from t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Cloning https://github.com/google/seqio to /tmp/pip-install-9x5viual/seqio_1a824e108a4b4800a91ef84f2d0e2cc4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google/seqio /tmp/pip-install-9x5viual/seqio_1a824e108a4b4800a91ef84f2d0e2cc4\n",
            "  Resolved https://github.com/google/seqio to commit 49213270cc20aaafaa06814502aad655d9275936\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cached_property (from t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Downloading cached_property-2.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fiddle>=0.2.5 (from t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Downloading fiddle-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting tensorflow-cpu (from t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Downloading tensorflow_cpu-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0) (6.31.1)\n",
            "Collecting tf-keras-nightly (from tf-hub-nightly->magenta_rt==0.2.0)\n",
            "  Downloading tf_keras_nightly-2.20.0.dev2025062209-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting astunparse>=1.6.0 (from tf-nightly->magenta_rt==0.2.0)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tf-nightly->magenta_rt==0.2.0)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tf-nightly->magenta_rt==0.2.0) (0.6.0)\n",
            "Collecting google_pasta>=0.1.1 (from tf-nightly->magenta_rt==0.2.0)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tf-nightly->magenta_rt==0.2.0)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tf-nightly->magenta_rt==0.2.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly->magenta_rt==0.2.0) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tf-nightly->magenta_rt==0.2.0) (1.74.0)\n",
            "Collecting tb-nightly~=2.20.0.a (from tf-nightly->magenta_rt==0.2.0)\n",
            "  Downloading tb_nightly-2.20.0a20250717-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting keras-nightly>=3.10.0.dev (from tf-nightly->magenta_rt==0.2.0)\n",
            "  Downloading keras_nightly-3.11.0.dev2025080804-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly->magenta_rt==0.2.0) (3.14.0)\n",
            "Collecting tensorflow>=2.17.0 (from tf2jax->magenta_rt==0.2.0)\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tf-nightly->magenta_rt==0.2.0)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->magenta_rt==0.2.0) (2.22)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0) (25.3.0)\n",
            "Collecting graphviz (from fiddle>=0.2.5->t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting libcst (from fiddle>=0.2.5->t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Downloading libcst-1.8.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->magenta_rt==0.2.0) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->magenta_rt==0.2.0) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->magenta_rt==0.2.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->magenta_rt==0.2.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->magenta_rt==0.2.0) (4.9.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras-nightly>=3.10.0.dev->tf-nightly->magenta_rt==0.2.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras-nightly>=3.10.0.dev->tf-nightly->magenta_rt==0.2.0) (0.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->magenta_rt==0.2.0) (0.44.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax->magenta_rt==0.2.0) (1.6.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax->magenta_rt==0.2.0) (24.1.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax->magenta_rt==0.2.0) (4.12.3)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax->magenta_rt==0.2.0) (3.20.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->magenta_rt==0.2.0) (4.3.8)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax->magenta_rt==0.2.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax->magenta_rt==0.2.0) (2.19.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->magenta_rt==0.2.0) (3.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tb-nightly~=2.20.0.a->tf-nightly->magenta_rt==0.2.0) (3.3.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tb-nightly~=2.20.0.a->tf-nightly->magenta_rt==0.2.0) (11.3.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tb-nightly~=2.20.0.a->tf-nightly->magenta_rt==0.2.0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tb-nightly~=2.20.0.a->tf-nightly->magenta_rt==0.2.0)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting protobuf>=3.20 (from tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0)\n",
            "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow>=2.17.0->tf2jax->magenta_rt==0.2.0)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.17.0->tf2jax->magenta_rt==0.2.0) (3.10.0)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow>=2.17.0->tf2jax->magenta_rt==0.2.0)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting grain==0.2.0 (from airio@ git+https://github.com/google/airio#egg=airio->t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Downloading grain-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from grain==0.2.0->airio@ git+https://github.com/google/airio#egg=airio->t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0) (3.1.1)\n",
            "Collecting jaxtyping (from grain==0.2.0->airio@ git+https://github.com/google/airio#egg=airio->t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting more-itertools>=9.1.0 (from grain==0.2.0->airio@ git+https://github.com/google/airio#egg=airio->t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Downloading more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->clu@ git+https://github.com/google/CommonLoopUtils#egg=clu->t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0) (2025.7.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->clu@ git+https://github.com/google/CommonLoopUtils#egg=clu->t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->clu@ git+https://github.com/google/CommonLoopUtils#egg=clu->t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0) (3.23.0)\n",
            "Requirement already satisfied: docstring-parser>=0.12 in /usr/local/lib/python3.11/dist-packages (from pyglove->seqio->magenta_rt==0.2.0) (0.17.0)\n",
            "Collecting tf-nightly (from magenta_rt==0.2.0)\n",
            "  Downloading tf_nightly-2.20.0.dev20250716-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting tb-nightly~=2.19.0.a (from tf-nightly->magenta_rt==0.2.0)\n",
            "  Downloading tb_nightly-2.19.0a20250218-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly==4.9.2.dev202308090034->seqio->magenta_rt==0.2.0) (0.8.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->magenta_rt==0.2.0) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage->magenta_rt==0.2.0) (0.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.20.0.a->tf-nightly->magenta_rt==0.2.0) (3.0.2)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping->grain==0.2.0->airio@ git+https://github.com/google/airio#egg=airio->t5x@ git+https://github.com/google-research/t5x.git@92c5b46->magenta_rt==0.2.0)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Downloading jax-0.6.2-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.6.2-cp311-cp311-manylinux2014_x86_64.whl (89.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libtpu-0.0.17-py3-none-manylinux_2_31_x86_64.whl (135.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.2/135.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tfds_nightly-4.9.2.dev202308090034-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text_nightly-2.20.0.dev20250619-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (96.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_hub_nightly-0.17.0.dev202506230306-py2.py3-none-any.whl (30 kB)\n",
            "Downloading tf2jax-0.3.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aqtp-0.9.0-py3-none-any.whl (901 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m901.6/901.6 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading fiddle-0.3.0-py3-none-any.whl (419 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_nightly-3.11.0.dev2025080804-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grain-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (417 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m417.8/417.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cached_property-2.0.1-py3-none-any.whl (7.4 kB)\n",
            "Downloading editdistance-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyglove-0.4.5-py3-none-any.whl (698 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_cpu-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (251.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m251.8/251.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras_nightly-2.20.0.dev2025062209-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_nightly-2.20.0.dev20250716-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m620.6/620.6 MB\u001b[0m \u001b[31m369.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tb_nightly-2.19.0a20250218-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libcst-1.8.2-cp311-cp311-manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: magenta_rt, flaxformer, t5x, flax, clu, seqio, airio, jestimator, optax\n",
            "  Building editable for magenta_rt (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for magenta_rt: filename=magenta_rt-0.2.0-0.editable-py3-none-any.whl size=14060 sha256=60a5dc0d6d7dddb804298c36bf5e552e2e065e789300dcdfcceb15b5b0d06899\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c3ig8w_a/wheels/9f/56/58/99534e395a4028917593b811d65a6e587e7bd84629d5f755f8\n",
            "  Building wheel for flaxformer (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flaxformer: filename=flaxformer-0.8.8-py3-none-any.whl size=323702 sha256=a8482f6f71399abdaf5d2333df916ad412deba8356050c6c6cb51394b673e480\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c3ig8w_a/wheels/63/d0/66/163798995ec0b386e8894cba03e4fd11c26436e94f4918e246\n",
            "  Building wheel for t5x (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for t5x: filename=t5x-0.0.0-py3-none-any.whl size=544091 sha256=26baf245d95a07ab854cadd4674aa2ca535d9dd04ab9d70cca7729c5df1f827c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c3ig8w_a/wheels/d3/76/f6/c8494d8d02d6761d1fd6eb0062888d42706af98d09ce3f9c97\n",
            "  Building wheel for flax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flax: filename=flax-0.11.1-py3-none-any.whl size=457498 sha256=bc57a596719586173b4e9b5f138f6d51b65a8e3f517725edd591faf2215fc3c8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c3ig8w_a/wheels/01/9f/4c/80002f7eaa05b97888e426d3e09b3d20353e2fe14afabd4263\n",
            "  Building wheel for clu (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clu: filename=clu-0.0.12-py3-none-any.whl size=103920 sha256=747fa3d83f731f33ec70126ae72affa49315e8fee946f3c865cd7cf4ca70ea7c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c3ig8w_a/wheels/1b/a2/f5/87ff130921476b6c2f37abdb1be713e13295753ade336535bc\n",
            "  Building wheel for seqio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqio: filename=seqio-0.0.18-py3-none-any.whl size=357688 sha256=2321385e9d742b659890a3bf1a2724b34763ba30798a74b484ee87030fc394ac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c3ig8w_a/wheels/34/f7/da/4145ad1ddd37eec38be59e93d280bf4d9e7063827a7b1447fc\n",
            "  Building wheel for airio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for airio: filename=airio-0.0.1-py3-none-any.whl size=119547 sha256=658ecba5fd0b1d65d81541f172ff1acd1f5e0181eed845a9e67474c441ae7b60\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c3ig8w_a/wheels/30/62/43/f2d3cfbebbf764a6f6011b640ac2b622526af1055d6140d4e4\n",
            "  Building wheel for jestimator (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jestimator: filename=jestimator-0.3.3-py3-none-any.whl size=2114114 sha256=1e87aec56257d91cf24995f22ff1099e0db916b4504868ba49710d98baef5da9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c3ig8w_a/wheels/6f/cd/d9/5a39ad2ca11c468460b217a6760f5f04621cfb3d300110a788\n",
            "  Building wheel for optax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optax: filename=optax-0.2.6.dev0-py3-none-any.whl size=355614 sha256=ec322d3ef58cf6b61f753b38a12f7fb150247f7f5610e1014c01aaab4b7d709e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c3ig8w_a/wheels/2b/eb/eb/495e8868435caef45b45519c8c5da60d047bdf1ac69826d1e3\n",
            "Successfully built magenta_rt flaxformer t5x flax clu seqio airio jestimator optax\n",
            "Installing collected packages: tensorflow-text-nightly, libtpu, libclang, gin-config, flatbuffers, wheel, werkzeug, wadler-lindig, tensorflow-io-gcs-filesystem, tensorboard-data-server, pyglove, protobuf, more-itertools, ml-collections, libcst, graphviz, google_pasta, editdistance, cached_property, tensorboard, tb-nightly, resampy, jaxtyping, jaxlib, fiddle, astunparse, keras-nightly, jax, tf-nightly, tensorflow-cpu, tensorflow, grain, tfds-nightly, tf2jax, tf-keras-nightly, tensorflow-text, optax, tf-hub-nightly, flax, jestimator, clu, aqtp, seqio, flaxformer, airio, t5x, magenta_rt\n",
            "  Attempting uninstall: libtpu\n",
            "    Found existing installation: libtpu 0.0.7.1\n",
            "    Uninstalling libtpu-0.0.7.1:\n",
            "      Successfully uninstalled libtpu-0.0.7.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.31.1\n",
            "    Uninstalling protobuf-6.31.1:\n",
            "      Successfully uninstalled protobuf-6.31.1\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 8.10.0\n",
            "    Uninstalling more-itertools-8.10.0:\n",
            "      Successfully uninstalled more-itertools-8.10.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.3\n",
            "    Uninstalling jaxlib-0.5.3:\n",
            "      Successfully uninstalled jaxlib-0.5.3\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.3\n",
            "    Uninstalling jax-0.5.3:\n",
            "      Successfully uninstalled jax-0.5.3\n",
            "  Attempting uninstall: optax\n",
            "    Found existing installation: optax 0.2.5\n",
            "    Uninstalling optax-0.2.5:\n",
            "      Successfully uninstalled optax-0.2.5\n",
            "  Attempting uninstall: flax\n",
            "    Found existing installation: flax 0.10.6\n",
            "    Uninstalling flax-0.10.6:\n",
            "      Successfully uninstalled flax-0.10.6\n",
            "Successfully installed airio-0.0.1 aqtp-0.9.0 astunparse-1.6.3 cached_property-2.0.1 clu-0.0.12 editdistance-0.8.1 fiddle-0.3.0 flatbuffers-25.2.10 flax-0.11.1 flaxformer-0.8.8 gin-config-0.5.0 google_pasta-0.2.0 grain-0.2.0 graphviz-0.21 jax-0.6.2 jaxlib-0.6.2 jaxtyping-0.3.2 jestimator-0.3.3 keras-nightly-3.11.0.dev2025080804 libclang-18.1.1 libcst-1.8.2 libtpu-0.0.17 magenta_rt-0.2.0 ml-collections-1.1.0 more-itertools-10.7.0 optax-0.2.6.dev0 protobuf-5.29.5 pyglove-0.4.5 resampy-0.4.3 seqio-0.0.18 t5x-0.0.0 tb-nightly-2.19.0a20250218 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-cpu-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-text-2.19.0 tensorflow-text-nightly-2.20.0.dev20250619 tf-hub-nightly-0.17.0.dev202506230306 tf-keras-nightly-2.20.0.dev2025062209 tf-nightly-2.20.0.dev20250716 tf2jax-0.3.7 tfds-nightly-4.9.2.dev202308090034 wadler-lindig-0.1.7 werkzeug-3.1.3 wheel-0.45.1\n",
            "Found existing installation: tensorflow 2.19.0\n",
            "Uninstalling tensorflow-2.19.0:\n",
            "  Successfully uninstalled tensorflow-2.19.0\n",
            "Found existing installation: tf_nightly 2.20.0.dev20250716\n",
            "Uninstalling tf_nightly-2.20.0.dev20250716:\n",
            "  Successfully uninstalled tf_nightly-2.20.0.dev20250716\n",
            "Found existing installation: tensorflow_cpu 2.19.0\n",
            "Uninstalling tensorflow_cpu-2.19.0:\n",
            "  Successfully uninstalled tensorflow_cpu-2.19.0\n",
            "\u001b[33mWARNING: Skipping tf-nightly-cpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-tpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tf-nightly-tpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-hub as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: tf-hub-nightly 0.17.0.dev202506230306\n",
            "Uninstalling tf-hub-nightly-0.17.0.dev202506230306:\n",
            "  Successfully uninstalled tf-hub-nightly-0.17.0.dev202506230306\n",
            "Found existing installation: tensorflow-text 2.19.0\n",
            "Uninstalling tensorflow-text-2.19.0:\n",
            "  Successfully uninstalled tensorflow-text-2.19.0\n",
            "Found existing installation: tensorflow-text-nightly 2.20.0.dev20250619\n",
            "Uninstalling tensorflow-text-nightly-2.20.0.dev20250619:\n",
            "  Successfully uninstalled tensorflow-text-nightly-2.20.0.dev20250619\n",
            "Collecting tf-nightly==2.20.0.dev20250619\n",
            "  Downloading tf_nightly-2.20.0.dev20250619-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting tensorflow-text-nightly==2.20.0.dev20250316\n",
            "  Downloading tensorflow_text_nightly-2.20.0.dev20250316-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting tf-hub-nightly\n",
            "  Using cached tf_hub_nightly-0.17.0.dev202506230306-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (25.0)\n",
            "Requirement already satisfied: protobuf>=4.21.6 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (1.74.0)\n",
            "Requirement already satisfied: tb-nightly~=2.19.0.a in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (2.19.0a20250218)\n",
            "Requirement already satisfied: keras-nightly>=3.6.0.dev in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (3.11.0.dev2025080804)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (3.14.0)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tf-nightly==2.20.0.dev20250619) (0.5.3)\n",
            "Requirement already satisfied: tf-keras-nightly in /usr/local/lib/python3.11/dist-packages (from tf-hub-nightly) (2.20.0.dev2025062209)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tf-nightly==2.20.0.dev20250619) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly==2.20.0.dev20250619) (14.1.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly==2.20.0.dev20250619) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly==2.20.0.dev20250619) (0.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tf-nightly==2.20.0.dev20250619) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tf-nightly==2.20.0.dev20250619) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tf-nightly==2.20.0.dev20250619) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tf-nightly==2.20.0.dev20250619) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly==2.20.0.dev20250619) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly==2.20.0.dev20250619) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly==2.20.0.dev20250619) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.19.0.a->tf-nightly==2.20.0.dev20250619) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly==2.20.0.dev20250619) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly==2.20.0.dev20250619) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nightly>=3.6.0.dev->tf-nightly==2.20.0.dev20250619) (0.1.2)\n",
            "Downloading tf_nightly-2.20.0.dev20250619-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (616.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m616.0/616.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text_nightly-2.20.0.dev20250316-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tf_hub_nightly-0.17.0.dev202506230306-py2.py3-none-any.whl (30 kB)\n",
            "Installing collected packages: tensorflow-text-nightly, tf-nightly, tf-hub-nightly\n"
          ]
        }
      ],
      "source": [
        "# @title Run this cell to install dependencies (~5 minutes)\n",
        "# @markdown Make sure you are running on **`v2-8 TPU` runtime** via `Runtime > Change Runtime Type`\n",
        "\n",
        "# @markdown Colab may prompt you to restart session. **Wait until the cell finishes running to restart**!\n",
        "\n",
        "# Clone library\n",
        "!git clone https://github.com/magenta/magenta-realtime.git\n",
        "\n",
        "# Magenta RT requires nightly TF builds, but stable may be installed.\n",
        "# Force nightly to take precedence by uninstalling and reinstalling.\n",
        "# Temporary workaround until MusicCoCa supported by TF stable.\n",
        "_all_tf = 'tensorflow tf-nightly tensorflow-cpu tf-nightly-cpu tensorflow-tpu tf-nightly-tpu tensorflow-hub tf-hub-nightly tensorflow-text tensorflow-text-nightly'\n",
        "_nightly_tf = 'tf-nightly==2.20.0.dev20250619 tensorflow-text-nightly==2.20.0.dev20250316 tf-hub-nightly'\n",
        "\n",
        "# Install library and dependencies\n",
        "# If running on TPU (recommended, runs on free tier Colab TPUs):\n",
        "!pip install -e magenta-realtime/[tpu] && pip uninstall -y {_all_tf} && pip install {_nightly_tf}\n",
        "# Uncomment if running on GPU (requires A100 via Colab Pro):\n",
        "# !pip install -e magenta-realtime/[gpu] && pip uninstall -y {_all_tf} && pip install {_nightly_tf}\n",
        "\n",
        "# Download the example of pre-recorded music\n",
        "GS_EXAMPLES_DIR = 'gs://magenta-rt-public/colab_examples'\n",
        "!gsutil cp -R $GS_EXAMPLES_DIR /content/ &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1OI3L16olYQs"
      },
      "outputs": [],
      "source": [
        "# @title Run this cell to initialize model (~5 minutes)\n",
        "\n",
        "import os\n",
        "\n",
        "import concurrent.futures\n",
        "import dataclasses\n",
        "import functools\n",
        "from google.colab import files\n",
        "import ipywidgets as ipw\n",
        "import IPython.display as ipd\n",
        "import jax\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tempfile\n",
        "from typing import Optional, Sequence, Tuple\n",
        "import warnings\n",
        "\n",
        "from magenta_rt import audio as audio_lib\n",
        "from magenta_rt import musiccoca\n",
        "from magenta_rt import spectrostream\n",
        "from magenta_rt import system\n",
        "from magenta_rt import utils\n",
        "from magenta_rt.colab import prompt_types\n",
        "from magenta_rt.colab import utils as colab_utils\n",
        "from magenta_rt.colab import widgets\n",
        "\n",
        "\n",
        "# ========= Helper functions ===========\n",
        "\n",
        "def load_audio(audio_filename, sample_rate):\n",
        "  \"\"\"Loads an audio file.\n",
        "\n",
        "  Args:\n",
        "    audio_filename: File path to load.\n",
        "    sample_rate: The number of samples per second at which the audio will be\n",
        "        returned. Resampling will be performed if necessary.\n",
        "\n",
        "  Returns:\n",
        "    A numpy array of audio samples, sampled at the specified rate, in float32\n",
        "    format.\n",
        "  \"\"\"\n",
        "  y, unused_sr = librosa.load(audio_filename, sr=sample_rate, mono=False)\n",
        "  return y\n",
        "\n",
        "\n",
        "def wav_data_to_samples_librosa(audio_file, sample_rate):\n",
        "  \"\"\"Loads an in-memory audio file with librosa.\n",
        "\n",
        "  Use this instead of wav_data_to_samples if the wav is 24-bit, as that's\n",
        "  incompatible with wav_data_to_samples internal scipy call.\n",
        "\n",
        "  Will copy to a local temp file before loading so that librosa can read a file\n",
        "  path. Librosa does not currently read in-memory files.\n",
        "\n",
        "  It will be treated as a .wav file.\n",
        "\n",
        "  Args:\n",
        "    audio_file: Wav file to load.\n",
        "    sample_rate: The number of samples per second at which the audio will be\n",
        "        returned. Resampling will be performed if necessary.\n",
        "\n",
        "  Returns:\n",
        "    A numpy array of audio samples, single-channel (mono) and sampled at the\n",
        "    specified rate, in float32 format.\n",
        "  \"\"\"\n",
        "  with tempfile.NamedTemporaryFile(suffix='.wav') as wav_input_file:\n",
        "    wav_input_file.write(audio_file)\n",
        "    # Before copying the file, flush any contents\n",
        "    wav_input_file.flush()\n",
        "    # And back the file position to top (not need for Copy but for certainty)\n",
        "    wav_input_file.seek(0)\n",
        "    return load_audio(wav_input_file.name, sample_rate)\n",
        "\n",
        "\n",
        "def get_metronome_audio(\n",
        "    loop_samples: int,\n",
        "    beats_per_loop: int,\n",
        "    sample_rate: int,\n",
        "    chunk_samples: int):\n",
        "  \"\"\"Generates metronome audio.\n",
        "\n",
        "  Args:\n",
        "    loop_samples: The number of samples in a loop.\n",
        "    beats_per_loop: The number of beats in a loop.\n",
        "    sample_rate: The sample rate of the audio.\n",
        "    chunk_samples: The number of samples in a chunk.\n",
        "\n",
        "  Returns:\n",
        "    A numpy array of metronome audio samples.\n",
        "  \"\"\"\n",
        "  metronome_audio = np.zeros((loop_samples,))\n",
        "  BEEP_SECONDS = 0.04\n",
        "  BEEP_VOLUME = 0.25\n",
        "  beeps = []\n",
        "  for freq in (880, 440):\n",
        "    beeps.append(BEEP_VOLUME * np.sin(np.linspace(\n",
        "        0,\n",
        "        2 * np.pi * freq * BEEP_SECONDS,\n",
        "        int(BEEP_SECONDS * sample_rate))))\n",
        "  ramp_samples = 100\n",
        "  beep_envelope = np.concat(\n",
        "      [np.linspace(0, 1, ramp_samples),\n",
        "       np.ones((int(BEEP_SECONDS * sample_rate) - 2 * ramp_samples,)),\n",
        "       np.linspace(1, 0, ramp_samples)])\n",
        "  for i in range(len(beeps)):\n",
        "    beeps[i] *= beep_envelope\n",
        "  beat_length = loop_samples // beats_per_loop\n",
        "  for i in range(beats_per_loop):\n",
        "    beep = beeps[0 if i == 0 else 1]\n",
        "    metronome_audio[i * beat_length:i * beat_length + len(beep)] = beep\n",
        "  # Add an extra buffer to the metronome audio to make slicing easier later.\n",
        "  return np.concat([metronome_audio, metronome_audio[:chunk_samples]])\n",
        "\n",
        "\n",
        "# ================ Model System ======================\n",
        "class MagentaRTCFGTied(system.MagentaRTT5X):\n",
        "  \"\"\"Magenta RT T5X system with \"tied\" CFG controlling input and style.\"\"\"\n",
        "\n",
        "  # This method is mostly identical to system.MagentaRTT5X.generate_chunk, but\n",
        "  # adds \"tied\" CFG that acts jointly on input and style. Negative input tokens\n",
        "  # are passed as `context_tokens_orig`.\n",
        "  def generate_chunk(\n",
        "      self,\n",
        "      state: Optional[system.MagentaRTState] = None,\n",
        "      style: Optional[musiccoca.StyleEmbedding] = None,\n",
        "      seed: Optional[int] = None,\n",
        "      **kwargs,\n",
        "  ) -> Tuple[audio_lib.Waveform, system.MagentaRTState]:\n",
        "    \"\"\"Generates a chunk of audio and returns updated state.\n",
        "\n",
        "    Args:\n",
        "      state: The current state of the system.\n",
        "      style: The style embedding to use for the generation.\n",
        "      seed: The seed to use for the generation.\n",
        "      **kwargs: Additional keyword arguments for sampling params, e.g.\n",
        "        temperature, topk, guidance_weight, max_decode_frames.\n",
        "\n",
        "    Returns:\n",
        "      A tuple of the generated audio and the updated state.\n",
        "    \"\"\"\n",
        "    # Init state, style, and seed (if not provided)\n",
        "    if state is None:\n",
        "      state = self.init_state()\n",
        "    if seed is None:\n",
        "      seed = np.random.randint(0, 2**31)\n",
        "\n",
        "    context_tokens = {\n",
        "        \"orig\": kwargs.get(\"context_tokens_orig\", state.context_tokens),\n",
        "        \"mix\": state.context_tokens,\n",
        "    }\n",
        "    codec_tokens_lm = {}\n",
        "    for key, tokens in context_tokens.items():\n",
        "      # Prepare codec tokens for LLM\n",
        "      codec_tokens_lm[key] = np.where(\n",
        "          tokens >= 0,\n",
        "          utils.rvq_to_llm(\n",
        "              np.maximum(tokens, 0),\n",
        "              self.config.codec_rvq_codebook_size,\n",
        "              self.config.vocab_codec_offset,\n",
        "          ),\n",
        "          np.full_like(tokens, self.config.vocab_mask_token),\n",
        "      )\n",
        "      assert (\n",
        "          codec_tokens_lm[key].shape == self.config.context_tokens_shape\n",
        "      )  # (250, 16)\n",
        "      assert (\n",
        "          codec_tokens_lm[key].min() >= self.config.vocab_mask_token\n",
        "          and codec_tokens_lm[key].max()\n",
        "          < (self.config.vocab_codec_offset + self.config.vocab_codec_size)\n",
        "      )  # check range [1, 16386)\n",
        "\n",
        "    # Prepare style tokens for LLM\n",
        "    if style is None:\n",
        "      style_tokens_lm = np.full(\n",
        "          (self.config.encoder_style_rvq_depth,),\n",
        "          self.config.vocab_mask_token,\n",
        "          dtype=np.int32,\n",
        "      )\n",
        "    else:\n",
        "      if style.shape != (self.style_model.config.embedding_dim,):\n",
        "        raise ValueError(f\"Invalid style shape: {style.shape}\")\n",
        "      style_tokens = self.style_model.tokenize(style)\n",
        "      assert style_tokens.shape == (self.style_model.config.rvq_depth,)\n",
        "      style_tokens = style_tokens[: self.config.encoder_style_rvq_depth]\n",
        "      style_tokens_lm = utils.rvq_to_llm(\n",
        "          style_tokens,\n",
        "          self.config.style_rvq_codebook_size,\n",
        "          self.config.vocab_style_offset,\n",
        "      )\n",
        "      assert (\n",
        "          style_tokens_lm.min() >= self.config.vocab_style_offset\n",
        "          and style_tokens_lm.max()\n",
        "          < (self.config.vocab_style_offset + self.config.vocab_style_size)\n",
        "      )  # check range [17140, 23554)\n",
        "    assert style_tokens_lm.shape == (\n",
        "        self.config.encoder_style_rvq_depth,\n",
        "    )  # (6,)\n",
        "\n",
        "    # Prepare encoder input\n",
        "    batch_size, _, _ = self._device_params\n",
        "    encoder_inputs_pos = np.concatenate(\n",
        "        [codec_tokens_lm[\"mix\"][\n",
        "            :, :self.config.encoder_codec_rvq_depth].reshape(-1),\n",
        "         style_tokens_lm\n",
        "        ],\n",
        "        axis=0,\n",
        "    )\n",
        "    assert encoder_inputs_pos.shape == (1006,)\n",
        "\n",
        "    # Construct negative using original context tokens, and masking style.\n",
        "    encoder_inputs_neg = np.concatenate(\n",
        "        [codec_tokens_lm[\"orig\"][\n",
        "            :, :self.config.encoder_codec_rvq_depth].reshape(-1),\n",
        "         style_tokens_lm\n",
        "        ],\n",
        "        axis=0,\n",
        "    )\n",
        "    encoder_inputs_neg[-self.config.encoder_style_rvq_depth:] = (\n",
        "        self.config.vocab_mask_token)\n",
        "    assert encoder_inputs_neg.shape == (1006,)\n",
        "\n",
        "    encoder_inputs = np.stack([encoder_inputs_pos, encoder_inputs_neg], axis=0)\n",
        "    assert encoder_inputs.shape == (2, 1006)\n",
        "\n",
        "    # Generate tokens / NLL scores.\n",
        "    max_decode_frames = kwargs.get(\n",
        "        \"max_decode_frames\", self.config.chunk_length_frames\n",
        "    )\n",
        "    generated_tokens, _ = self._llm(\n",
        "        {\n",
        "            \"encoder_input_tokens\": encoder_inputs,\n",
        "            \"decoder_input_tokens\": np.zeros(\n",
        "                (\n",
        "                    batch_size,\n",
        "                    self.config.chunk_length_frames\n",
        "                    * self.config.decoder_codec_rvq_depth,\n",
        "                ),\n",
        "                dtype=np.int32,\n",
        "            ),\n",
        "        },\n",
        "        {\n",
        "            \"max_decode_steps\": np.array(\n",
        "                max_decode_frames * self.config.decoder_codec_rvq_depth,\n",
        "                dtype=np.int32,\n",
        "            ),\n",
        "            \"guidance_weight\": kwargs.get(\n",
        "                \"guidance_weight\", self._guidance_weight\n",
        "            ),\n",
        "            \"temperature\": kwargs.get(\"temperature\", self._temperature),\n",
        "            \"topk\": kwargs.get(\"topk\", self._topk),\n",
        "        },\n",
        "        jax.random.PRNGKey(seed + state.chunk_index),\n",
        "    )\n",
        "\n",
        "    # Process generated tokens\n",
        "    generated_tokens = np.array(generated_tokens)\n",
        "    assert generated_tokens.shape == (\n",
        "        batch_size,\n",
        "        self.config.chunk_length_frames * self.config.decoder_codec_rvq_depth,\n",
        "    )\n",
        "    generated_tokens = generated_tokens[:1]  # larger batch sizes unsupported\n",
        "    generated_tokens = generated_tokens.reshape(\n",
        "        self.config.chunk_length_frames, self.config.decoder_codec_rvq_depth\n",
        "    )  # (50, 16)\n",
        "    generated_tokens = generated_tokens[:max_decode_frames]  # (N, 16)\n",
        "    with warnings.catch_warnings():\n",
        "      warnings.simplefilter(\"ignore\")\n",
        "      generated_rvq_tokens = utils.llm_to_rvq(\n",
        "          generated_tokens,\n",
        "          self.config.codec_rvq_codebook_size,\n",
        "          self.config.vocab_codec_offset,\n",
        "          safe=False,\n",
        "      )\n",
        "\n",
        "    # Decode via SpectroStream using additional frame of samples for crossfading\n",
        "    # We want to generate a 2s chunk with an additional 40ms of crossfade, which\n",
        "    # is one additional codec frame. Caller is responsible for actually applying\n",
        "    # the crossfade.\n",
        "    xfade_frames = state.context_tokens[-self.config.crossfade_length_frames :]\n",
        "    if state.chunk_index == 0:\n",
        "      # NOTE: This will create 40ms of gibberish at the beginning but it's OK.\n",
        "      xfade_frames = np.zeros_like(xfade_frames)\n",
        "    assert xfade_frames.min() >= 0\n",
        "    xfade_tokens = np.concatenate([xfade_frames, generated_rvq_tokens], axis=0)\n",
        "    assert xfade_tokens.shape == (\n",
        "        self.config.crossfade_length_frames + max_decode_frames,\n",
        "        self.config.decoder_codec_rvq_depth,\n",
        "    )  # (N+1, 16)\n",
        "    waveform = self.codec.decode(xfade_tokens)\n",
        "    assert isinstance(waveform, audio_lib.Waveform)\n",
        "    assert waveform.samples.shape == (\n",
        "        self.config.crossfade_length_samples\n",
        "        + max_decode_frames * self.config.frame_length_samples,\n",
        "        self.num_channels,\n",
        "    )  # ((N+1)*1920, 2)\n",
        "\n",
        "    # Update state\n",
        "    state.update(generated_rvq_tokens)\n",
        "\n",
        "    return (waveform, state)\n",
        "\n",
        "\n",
        "spectrostream_model = spectrostream.SpectroStreamJAX(lazy=False)\n",
        "\n",
        "SAMPLE_RATE = 48000\n",
        "CHUNK_SECONDS = 2.0\n",
        "CHUNK_SAMPLES = int(CHUNK_SECONDS * SAMPLE_RATE)\n",
        "INPUT_AUDIO = None\n",
        "\n",
        "# Fetch checkpoints and initialize model (may take up to 5 minutes)\n",
        "MRT = MagentaRTCFGTied(tag=\"large\", device=\"tpu:v2-8\", lazy=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "werlZh98wPVY"
      },
      "source": [
        "# Step 2: ğŸµ Stream music with audio injection! ğŸ¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4UEZRI4969AJ"
      },
      "outputs": [],
      "source": [
        "# @title Input settings\n",
        "\n",
        "# @markdown #### Select input source: ğŸ’¾ Pre-recorded or ğŸ¤ Live Mic\n",
        "\n",
        "input_source = 'Pre-recorded' # @param ['Live Mic', 'Pre-recorded']\n",
        "use_prerecorded_input = (input_source == 'Pre-recorded')\n",
        "\n",
        "# @markdown #### ğŸ’¾ Choose pre-recorded input\n",
        "\n",
        "prerecorded_audio = \"Electronic Groove\" # @param [\"Electronic Groove\", \"Funk Guitar\", \"Upload your own\"]\n",
        "\n",
        "# @markdown #### ğŸ¤ Live mic calibration\n",
        "# @markdown * Use wired headphones\n",
        "# @markdown * Take headphones off and bring close to mic\n",
        "# @markdown * Click `start` and wait ~10s for measurement\n",
        "\n",
        "\n",
        "# === Calibration and Audio Upload ===\n",
        "def load_example(fname):\n",
        "    return load_audio(\n",
        "        os.path.join('/content/colab_examples', fname),\n",
        "        sample_rate=SAMPLE_RATE,\n",
        "    )\n",
        "\n",
        "\n",
        "if use_prerecorded_input:\n",
        "  print('Using Pre-recorded Input!')\n",
        "\n",
        "  if prerecorded_audio == \"Electronic Groove\":\n",
        "    audio_samples = load_example(\"antoines_groove.mp3\")\n",
        "\n",
        "  if prerecorded_audio == \"Funk Guitar\":\n",
        "    audio_samples = load_example(\"jesses_funk_guitar.mp3\")\n",
        "\n",
        "  if prerecorded_audio == \"Upload your own\":\n",
        "    # Upload audio file\n",
        "    audio_data = list(files.upload().values())[0]\n",
        "    audio_samples = wav_data_to_samples_librosa(\n",
        "        audio_data,\n",
        "        sample_rate=SAMPLE_RATE,\n",
        "    )\n",
        "\n",
        "  # Postprocess\n",
        "  if audio_samples.ndim == 2:\n",
        "    audio_samples = audio_samples.T\n",
        "  else:\n",
        "    audio_samples = np.tile(audio_samples[:, None], 2)\n",
        "\n",
        "  print(\"First 10s of input audio:\")\n",
        "  ipd.display(ipd.Audio(audio_samples[:SAMPLE_RATE * 10].T, rate=SAMPLE_RATE))\n",
        "\n",
        "  # Add one buffer of looped audio to make slicing easier later.\n",
        "  INPUT_AUDIO = np.concat([audio_samples, audio_samples[:CHUNK_SAMPLES]])\n",
        "\n",
        "else:\n",
        "  print('Using Live Mic Input!')\n",
        "  # Calibrate latency.\n",
        "  latency_estimator = colab_utils.LatencyEstimator(\n",
        "    rate=SAMPLE_RATE,\n",
        "    buffer_size=int(SAMPLE_RATE * CHUNK_SECONDS),\n",
        "    duration=1,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LVLb4ywQUYgx"
      },
      "outputs": [],
      "source": [
        "# @title Metronome and Loop Settings\n",
        "\n",
        "# @markdown <ul>\n",
        "# @markdown <li>ğŸ¤ <b>Live Mic</b>: You'll perform a few intro loops to a metronome.</li>\n",
        "# @markdown <li>ğŸ’¾ <b>Pre-recorded Input</b>: The model will join after a few intro loops.</li>\n",
        "# @markdown </ul>\n",
        "\n",
        "# @markdown Beats per minute (BPM) used for metronome:\n",
        "bpm = 120  # @param {type: \"number\"}\n",
        "\n",
        "# @markdown Mic audio is delayed by one loop of this many beats:\n",
        "beats_per_loop = 8  # @param {\"type\":\"slider\",\"min\":1,\"max\":16,\"step\":1}\n",
        "\n",
        "loop_seconds = beats_per_loop * 60 / bpm\n",
        "loop_samples = int(loop_seconds * SAMPLE_RATE)\n",
        "\n",
        "# @markdown How many loops before the model joins in:\n",
        "\n",
        "intro_loops = 4  # @param {\"type\":\"slider\",\"min\":1,\"max\":5,\"step\":1}\n",
        "\n",
        "\n",
        "METRONOME_AUDIO = get_metronome_audio(loop_samples, beats_per_loop, SAMPLE_RATE, CHUNK_SAMPLES)\n",
        "\n",
        "print(f'Model will join in after {intro_loops * loop_seconds:.2f} seconds')\n",
        "\n",
        "\n",
        "# === Advanced settings ===\n",
        "\n",
        "# Extra prefix frames to include in the input+output mix that will be encoded.\n",
        "# These may be used to update the model context.\n",
        "MIX_PREFIX_FRAMES = 16\n",
        "\n",
        "# Frames to trim from the left of the input+output mix before updating the\n",
        "# model context, to avoid edge artifacts.\n",
        "LEFT_EDGE_FRAMES_TO_REMOVE = 8\n",
        "assert LEFT_EDGE_FRAMES_TO_REMOVE <= MIX_PREFIX_FRAMES\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "owxwmtM_wr5m"
      },
      "outputs": [],
      "source": [
        "# @title â–¶ï¸ Run this cell to start demo (~1 minute first time)\n",
        "\n",
        "if not use_prerecorded_input:\n",
        "  assert latency_estimator.done, \"It looks like you forgot to run step 2!\"\n",
        "  latency_samples = latency_estimator.get_latency()\n",
        "  assert 0 < latency_samples - 2 * CHUNK_SAMPLES < 0.3 * SAMPLE_RATE, (\n",
        "      \"Bad latency measurement. Rerun step 2.\")\n",
        "\n",
        "\n",
        "class AudioFade:\n",
        "  \"\"\"Handles the cross fade between audio chunks.\n",
        "\n",
        "  Args:\n",
        "    chunk_size: Number of audio samples per predicted frame (current\n",
        "      SpectroStream models produces 25Hz frames corresponding to 1920 audio\n",
        "      samples at 48kHz)\n",
        "    num_chunks: Number of audio chunks to fade between.\n",
        "    stereo: Whether the predicted audio is stereo or mono.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, chunk_size: int, num_chunks: int, stereo: bool):\n",
        "    fade_size = chunk_size * num_chunks\n",
        "    self.fade_size = fade_size\n",
        "    self.num_chunks = num_chunks\n",
        "\n",
        "    self.previous_chunk = np.zeros(fade_size)\n",
        "    self.ramp = np.sin(np.linspace(0, np.pi / 2, fade_size)) ** 2\n",
        "\n",
        "    if stereo:\n",
        "      self.previous_chunk = self.previous_chunk[:, np.newaxis]\n",
        "      self.ramp = self.ramp[:, np.newaxis]\n",
        "\n",
        "  def reset(self):\n",
        "    self.previous_chunk = np.zeros_like(self.previous_chunk)\n",
        "\n",
        "  def __call__(self, chunk: np.ndarray) -> np.ndarray:\n",
        "    chunk[: self.fade_size] *= self.ramp\n",
        "    chunk[: self.fade_size] += self.previous_chunk\n",
        "    self.previous_chunk = chunk[-self.fade_size :] * np.flip(self.ramp)\n",
        "    return chunk[: -self.fade_size]\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class AudioInjectionState:\n",
        "  \"\"\"State management for Audio Injection.\"\"\"\n",
        "  # The most recent context window (10s) of audio tokens corresponding to the\n",
        "  # model's predicted output. These are parallel to `state.context_tokens` but\n",
        "  # that context has the input audio mixed in.\n",
        "  context_tokens_orig: np.ndarray\n",
        "  # Stores all audio input (mono for live input, stereo for prerecorded input)\n",
        "  all_inputs: np.ndarray\n",
        "  # Stores all audio output (stereo)\n",
        "  all_outputs: np.ndarray\n",
        "  # How many chunks of audio have been generated\n",
        "  step: int\n",
        "\n",
        "\n",
        "# TODO(nconstant): Consider factoring out methods shared with MagentaRTStreamer\n",
        "# from Magenta_RT_Demo.ipynb\n",
        "class AudioInjectionStreamer:\n",
        "  \"\"\"Audio streamer class for Magenta RT model with Audio Injection.\n",
        "\n",
        "  This class holds a pretrained Magenta RT model, a cross fade state, a\n",
        "  generation state, audio injection state, and an asynchronous executor to\n",
        "  handle prompt embedding without interrupting the audio thread.\n",
        "\n",
        "  Args:\n",
        "    system: A MagentaRTBase instance.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      system: system.MagentaRTBase,\n",
        "      sample_rate: int = 48000,\n",
        "      num_channels: int = 2,\n",
        "      buffer_size: int = 2 * 48000,\n",
        "      extra_buffering: int = 0\n",
        "  ):\n",
        "    config = system.config\n",
        "    self.system = system\n",
        "    self.audio_streamer = None\n",
        "    self.sample_rate = sample_rate\n",
        "    self.num_channels = num_channels\n",
        "    self.buffer_size = buffer_size\n",
        "    self.extra_buffering = extra_buffering\n",
        "    self.fade = AudioFade(\n",
        "        chunk_size=int(config.codec_sample_rate * config.crossfade_length),\n",
        "        num_chunks=1,\n",
        "        stereo=True\n",
        "    )\n",
        "    self.state = None\n",
        "    self.executor = concurrent.futures.ThreadPoolExecutor()\n",
        "    context_seconds = config.context_length\n",
        "    context_frames = int(context_seconds * config.codec_frame_rate)\n",
        "    context_samples = int(context_seconds * SAMPLE_RATE)\n",
        "    self.injection_state = AudioInjectionState(\n",
        "        context_tokens_orig=np.zeros(\n",
        "            (context_frames, config.decoder_codec_rvq_depth),\n",
        "            dtype=np.int32\n",
        "        ),\n",
        "        all_inputs=np.zeros(\n",
        "            (context_samples, 2)\n",
        "            if use_prerecorded_input else (context_samples,),\n",
        "            dtype=np.float32\n",
        "        ),\n",
        "        all_outputs=np.zeros((context_samples, 2), dtype=np.float32),\n",
        "        step=-1,  # This will be 0 after the warmup call.\n",
        "    )\n",
        "\n",
        "  @property\n",
        "  def warmup(self):\n",
        "    \"\"\"Returns whether to warm up the audio streamer.\"\"\"\n",
        "    return True\n",
        "\n",
        "  def on_stream_start(self):\n",
        "    \"\"\"Called when the UI starts streaming.\"\"\"\n",
        "    self.get_style_embedding(force_wait=False)\n",
        "    self.get_style_embedding(force_wait=True)\n",
        "    if self.audio_streamer is not None:\n",
        "      self.audio_streamer.reset_ring_buffer()\n",
        "\n",
        "  def on_stream_stop(self):\n",
        "    \"\"\"Called when the UI stops streaming.\"\"\"\n",
        "    pass\n",
        "\n",
        "  def reset(self):\n",
        "    self.state = None\n",
        "    self.fade.reset()\n",
        "    self.embed_style.cache_clear()\n",
        "    if self.audio_streamer is not None:\n",
        "      self.audio_streamer.reset_ring_buffer()\n",
        "\n",
        "  def start(self):\n",
        "    self.audio_streamer = colab_utils.AudioStreamer(\n",
        "        self,\n",
        "        rate=self.sample_rate,\n",
        "        buffer_size=self.buffer_size,\n",
        "        enable_input=True,\n",
        "        warmup=self.warmup,\n",
        "        raw_input_audio=True,\n",
        "        enable_automatic_gain_control_on_input=True,\n",
        "        num_output_channels=self.num_channels,\n",
        "        additional_buffered_samples=self.extra_buffering,\n",
        "        start_streaming_callback=self.on_stream_start,\n",
        "        stop_streaming_callback=self.on_stream_stop,\n",
        "    )\n",
        "    self.reset()\n",
        "\n",
        "  def stop(self):\n",
        "    self.executor.shutdown(wait=True)\n",
        "    if self.audio_streamer is not None:\n",
        "      del self.audio_streamer\n",
        "      self.audio_streamer = None\n",
        "\n",
        "  def global_ui_params(self):\n",
        "    return colab_utils.Parameters.get_values()\n",
        "\n",
        "  @functools.cache\n",
        "  def embed_style(self, style: str):\n",
        "    return self.executor.submit(self.system.embed_style, style)\n",
        "\n",
        "  @functools.cache\n",
        "  def embed_16k_audio(self, audio: tuple[float]):\n",
        "    \"\"\"Embed 16k audio asyncronously, returning a future.\"\"\"\n",
        "    audio = audio_lib.Waveform(np.asarray(audio), 16000)\n",
        "    return self.executor.submit(self.system.embed_style, audio)\n",
        "\n",
        "  def embed_48k_audio(self, audio: tuple[float]):\n",
        "    \"\"\"Embed 48k audio asyncronously, returning an embedding.\"\"\"\n",
        "    resampled_audio = resampy.resample(np.asarray(audio), 48000, 16000)\n",
        "    return self.embed_16k_audio(tuple(resampled_audio)).result()\n",
        "\n",
        "  def get_style_embedding(self, force_wait: bool = False):\n",
        "    prompts = self.get_prompts()\n",
        "    weighted_embedding = np.zeros((768,), dtype=np.float32)\n",
        "    total_weight = 0.0\n",
        "    for prompt_value, prompt_weight in prompts:\n",
        "      match type(prompt_value):\n",
        "        case prompt_types.TextPrompt:\n",
        "          if not prompt_value:\n",
        "            continue\n",
        "          embedding = self.embed_style(prompt_value)\n",
        "\n",
        "        case prompt_types.AudioPrompt:\n",
        "          embedding = self.embed_16k_audio(tuple(prompt_value.value))\n",
        "\n",
        "        case prompt_types.EmbeddingPrompt:\n",
        "          embedding = prompt_value.value\n",
        "\n",
        "        case _:\n",
        "          raise ValueError(f\"Unsupported prompt type: {type(prompt_value)}\")\n",
        "\n",
        "      if isinstance(embedding, concurrent.futures.Future):\n",
        "        if force_wait:\n",
        "          embedding.result()\n",
        "\n",
        "        if not embedding.done():\n",
        "          continue\n",
        "\n",
        "        embedding = embedding.result()\n",
        "\n",
        "      weighted_embedding += embedding * prompt_weight\n",
        "      total_weight += prompt_weight\n",
        "\n",
        "    if total_weight > 0:\n",
        "      weighted_embedding /= total_weight\n",
        "\n",
        "    return weighted_embedding\n",
        "\n",
        "  def get_prompts(self):\n",
        "    params = self.global_ui_params()\n",
        "    num_prompts = sum(map(lambda s: \"prompt_value\" in s, params.keys()))\n",
        "    prompts = []\n",
        "    for i in range(num_prompts):\n",
        "      prompt_weight = params[f\"prompt_weight_{i}\"]\n",
        "      prompt_value = params[f\"prompt_value_{i}\"]\n",
        "\n",
        "      if prompt_value is None or not prompt_weight:\n",
        "        continue\n",
        "\n",
        "      match type(prompt_value):\n",
        "        case prompt_types.TextPrompt:\n",
        "          prompt_value = prompt_value.strip()\n",
        "        case prompt_types.AudioPrompt:\n",
        "          pass\n",
        "        case prompt_types.EmbeddingPrompt:\n",
        "          pass\n",
        "        case _:\n",
        "          raise ValueError(f\"Unsupported prompt type: {type(prompt_value)}\")\n",
        "\n",
        "      prompts.append((prompt_value, prompt_weight))\n",
        "    return prompts\n",
        "\n",
        "  def generate(self, ui_params, inputs):\n",
        "    if use_prerecorded_input:\n",
        "      assert INPUT_AUDIO is not None, (\n",
        "          \"To use prerecorded input, first upload audio using step 4.\")\n",
        "      start = (self.injection_state.step * CHUNK_SAMPLES) % (\n",
        "          len(INPUT_AUDIO) - CHUNK_SAMPLES)\n",
        "      end = start + CHUNK_SAMPLES\n",
        "      inputs = INPUT_AUDIO[start:end]\n",
        "      inputs_mono = np.mean(inputs, axis=-1)\n",
        "\n",
        "    if LIVE_AUDIO_PROMPT is not None:\n",
        "      # Update live audio prompt with latest inputs.\n",
        "      LIVE_AUDIO_PROMPT.update_audio_input(\n",
        "          inputs_mono if use_prerecorded_input else inputs)\n",
        "\n",
        "    # Add this input chunk to the end of `all_inputs`.\n",
        "    self.injection_state.all_inputs = np.concatenate(\n",
        "        [self.injection_state.all_inputs, inputs], axis=0\n",
        "    )\n",
        "\n",
        "    # Pass an extra prefix of mixed audio to the encoder so we can throw away\n",
        "    # the earliest frames, which have edge artifacts.\n",
        "    mix_samples = (\n",
        "        CHUNK_SAMPLES + MIX_PREFIX_FRAMES\n",
        "        * self.system.config.frame_length_samples\n",
        "    )\n",
        "\n",
        "    # Input audio will be delayed by one loop before being mixed with model\n",
        "    # output.\n",
        "    beats_per_loop = ui_params[\"beats_per_loop\"]\n",
        "    loop_seconds = beats_per_loop * 60 / bpm\n",
        "    loop_samples = int(loop_seconds * SAMPLE_RATE)\n",
        "\n",
        "    # \"I/O offset\" is the number of samples by which we shift the inputs\n",
        "    # before mixing them with the outputs.\n",
        "    io_offset = CHUNK_SAMPLES - int(\n",
        "        streamer.system.config.crossfade_length * SAMPLE_RATE)\n",
        "    if not use_prerecorded_input:\n",
        "      io_offset += loop_samples - latency_samples\n",
        "      # TODO(nconstant): Support \"free\" mode by padding with silence instead of\n",
        "      # failing here.\n",
        "      assert io_offset >= 0, (\n",
        "          \"Increase `beats_per_loop` in the previous cell and rerun it.\")\n",
        "\n",
        "    # Select a window of input audio for mixing.\n",
        "    inputs_to_mix = self.injection_state.all_inputs[\n",
        "        -(io_offset + mix_samples):-io_offset]\n",
        "\n",
        "    # Select a window of output audio for mixing.\n",
        "    outputs_to_mix = self.injection_state.all_outputs[-mix_samples:]\n",
        "    outputs_to_mix *= ui_params.get(\"model_feedback\")\n",
        "\n",
        "    # Silence the last `input_gap_ms` ms of `inputs_to_mix`, to discourage\n",
        "    # copying the input verbatim.\n",
        "    input_gap_samples = int(SAMPLE_RATE * ui_params.get(\"input_gap\") / 1000)\n",
        "    ramp_samples = 100\n",
        "    ramp = np.linspace(1, 0, min(ramp_samples, input_gap_samples))\n",
        "    if use_prerecorded_input:\n",
        "      ramp = np.stack([ramp, ramp], axis=-1)\n",
        "    envelope = np.concat(\n",
        "        [np.ones_like(inputs_to_mix[input_gap_samples:]),\n",
        "         ramp,\n",
        "         np.zeros_like(inputs_to_mix[:max(0, input_gap_samples - ramp_samples)])\n",
        "        ]\n",
        "    )\n",
        "    inputs_to_mix = inputs_to_mix * envelope\n",
        "\n",
        "    # Mix input and output audio.\n",
        "    if not use_prerecorded_input:\n",
        "      inputs_to_mix = inputs_to_mix[:, None]\n",
        "    mix_audio = audio_lib.Waveform(\n",
        "        inputs_to_mix + outputs_to_mix,\n",
        "        sample_rate=SAMPLE_RATE\n",
        "    )\n",
        "    # Encode mix audio to tokens, and throw away a prefix.\n",
        "    mix_tokens = spectrostream_model.encode(mix_audio)[\n",
        "        LEFT_EDGE_FRAMES_TO_REMOVE:]\n",
        "\n",
        "    if self.state is not None:\n",
        "      self.injection_state.context_tokens_orig = self.state.context_tokens\n",
        "      self.state.context_tokens[-len(mix_tokens):] = mix_tokens[\n",
        "          :, :self.system.config.decoder_codec_rvq_depth]\n",
        "\n",
        "    max_decode_frames = round(\n",
        "        CHUNK_SECONDS * self.system.config.codec_frame_rate)\n",
        "\n",
        "    chunk, self.state = self.system.generate_chunk(\n",
        "        state=self.state,\n",
        "        style=self.get_style_embedding(),\n",
        "        seed=None,\n",
        "        max_decode_frames=max_decode_frames,\n",
        "        context_tokens_orig=self.injection_state.context_tokens_orig,\n",
        "        **ui_params,\n",
        "    )\n",
        "\n",
        "    # Add this chunk (before cross-fading) to the end of `all_outputs`.\n",
        "    # Note, we ignore the first frame of the chunk, which will be used for\n",
        "    # cross-fading.\n",
        "    self.injection_state.all_outputs = np.concatenate(\n",
        "        [self.injection_state.all_outputs,\n",
        "         chunk.samples[self.fade.fade_size:]]\n",
        "    )\n",
        "\n",
        "    chunk = self.fade(chunk.samples)\n",
        "    chunk *= ui_params.get(\"model_volume\")\n",
        "\n",
        "    if ui_params.get(\"metronome\"):\n",
        "      # Add metronome audio to output.\n",
        "      start = (self.injection_state.step * CHUNK_SAMPLES) % loop_samples\n",
        "      end = start + CHUNK_SAMPLES\n",
        "      metronome_chunk = METRONOME_AUDIO[start:end]\n",
        "      chunk += metronome_chunk[:, None]\n",
        "\n",
        "    if use_prerecorded_input:\n",
        "      chunk += inputs * ui_params.get(\"input_volume\")\n",
        "\n",
        "    # When intro loops are over, raise model volume and feedback.\n",
        "    if self.injection_state.step + 1 == int(\n",
        "        intro_loops * loop_samples / CHUNK_SAMPLES):\n",
        "      colab_utils.Parameters._UI_ELEMENTS[\"model_feedback\"].value = 0.95\n",
        "      colab_utils.Parameters._UI_ELEMENTS[\"model_volume\"].value = (\n",
        "          0.6 if use_prerecorded_input else 0.95)\n",
        "      if not use_prerecorded_input:\n",
        "         # Turn off metronome, and raise input gap.\n",
        "        colab_utils.Parameters._UI_ELEMENTS[\"metronome\"].value = False\n",
        "        colab_utils.Parameters._UI_ELEMENTS[\"input_gap\"].value = 400\n",
        "\n",
        "    self.injection_state.step += 1\n",
        "\n",
        "    return chunk\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    return self.generate(self.global_ui_params(), inputs)\n",
        "\n",
        "\n",
        "streamer = AudioInjectionStreamer(MRT, buffer_size=CHUNK_SAMPLES)\n",
        "\n",
        "\n",
        "def build_prompt_ui(\n",
        "    default_prompts: Sequence[str],\n",
        "    num_audio_prompt: int,\n",
        "    include_live_audio_prompt: bool = False):\n",
        "  \"\"\"Add interactive prompt widgets and register them.\"\"\"\n",
        "  prompts = []\n",
        "\n",
        "  if include_live_audio_prompt:\n",
        "    live_audio_prompt = widgets.LiveAudioPrompt(\n",
        "        streamer.embed_48k_audio,\n",
        "        sample_rate=48000,\n",
        "        trigger_embedding_every_n_seconds=0)\n",
        "    live_audio_prompt.slider.value = 0.1\n",
        "    prompts.append(live_audio_prompt)\n",
        "    prompts[-1].slider.value = 0.1\n",
        "  else:\n",
        "    live_audio_prompt = None\n",
        "\n",
        "  for p in default_prompts:\n",
        "    prompts.append(widgets.Prompt())\n",
        "    prompts[-1].text.value = p\n",
        "  prompts[-len(default_prompts)].slider.value = 1.0\n",
        "\n",
        "  # Add audio prompts\n",
        "  for _ in range(num_audio_prompt):\n",
        "    prompts.append(widgets.AudioPrompt())\n",
        "    prompts[-1].slider.value = 0.0\n",
        "\n",
        "  colab_utils.Parameters.register_ui_elements(\n",
        "      display=False,\n",
        "      **{f\"prompt_weight_{i}\": p.slider for i, p in enumerate(prompts)},\n",
        "      **{f\"prompt_value_{i}\": p.prompt_value for i, p in enumerate(prompts)},\n",
        "  )\n",
        "  return live_audio_prompt, [p.get_widget() for p in prompts]\n",
        "\n",
        "\n",
        "def build_sampling_option_ui():\n",
        "  \"\"\"Add interactive sampling option widgets and register them.\"\"\"\n",
        "  options = {\n",
        "      \"temperature\": ipw.FloatSlider(\n",
        "          min=0.0,\n",
        "          max=4.0,\n",
        "          step=0.01,\n",
        "          value=1.2,\n",
        "          description=\"temperature\",\n",
        "      ),\n",
        "      \"topk\": ipw.IntSlider(\n",
        "          min=0,\n",
        "          max=1024,\n",
        "          step=1,\n",
        "          value=30,\n",
        "          description=\"topk\",\n",
        "      ),\n",
        "      \"guidance_weight\": ipw.FloatSlider(\n",
        "          min=0.0,\n",
        "          max=10.0,\n",
        "          step=0.01,\n",
        "          value=1.5 if use_prerecorded_input else 0.8,\n",
        "          description=\"guidance\",\n",
        "      ),\n",
        "  }\n",
        "  if use_prerecorded_input:\n",
        "    options.update({\n",
        "        \"model_volume\": ipw.FloatSlider(\n",
        "            min=0.0,\n",
        "            max=1.0,\n",
        "            step=0.05,\n",
        "            value=0.0,\n",
        "            description=\"model vol.\",\n",
        "        ),\n",
        "        \"input_volume\": ipw.FloatSlider(\n",
        "            value=1.0,\n",
        "            min=0.0,\n",
        "            max=1.0,\n",
        "            step=0.05,\n",
        "            orientation=\"horizontal\",\n",
        "            description=\"input volume\",\n",
        "        ),\n",
        "    })\n",
        "  else:\n",
        "    options.update({\n",
        "        \"metronome\": ipw.Checkbox(\n",
        "            value=True,\n",
        "            description=\"metronome\",\n",
        "            indent=False,\n",
        "        ),\n",
        "    })\n",
        "\n",
        "  colab_utils.Parameters.register_ui_elements(display=False, **options)\n",
        "\n",
        "  return list(options.values())\n",
        "\n",
        "\n",
        "def build_hidden_option_ui():\n",
        "  \"\"\"Add interactive hidden option widgets and register them.\"\"\"\n",
        "  options = {\n",
        "      \"input_gap\": ipw.IntSlider(\n",
        "          value=0,\n",
        "          min=0,\n",
        "          max=2000,\n",
        "          step=100,\n",
        "          orientation=\"horizontal\",\n",
        "          description=\"input gap\",\n",
        "      ),\n",
        "      \"beats_per_loop\": ipw.IntSlider(\n",
        "          min=0,\n",
        "          max=16,\n",
        "          step=1,\n",
        "          value=beats_per_loop,\n",
        "          description=\"beats/loop\",\n",
        "      ),\n",
        "      \"model_feedback\": ipw.FloatSlider(\n",
        "          min=0.0,\n",
        "          max=1.0,\n",
        "          step=0.05,\n",
        "          value=0.0,\n",
        "          description=\"model feedback\",\n",
        "      ),\n",
        "  }\n",
        "  if not use_prerecorded_input:\n",
        "    options.update({\n",
        "        \"model_volume\": ipw.FloatSlider(\n",
        "            min=0.0,\n",
        "            max=1.0,\n",
        "            step=0.05,\n",
        "            value=0.0,\n",
        "            description=\"model volume\",\n",
        "        ),\n",
        "    })\n",
        "\n",
        "  colab_utils.Parameters.register_ui_elements(display=False, **options)\n",
        "\n",
        "  return list(options.values())\n",
        "\n",
        "\n",
        "colab_utils.Parameters.reset()\n",
        "\n",
        "\n",
        "def _reset_state(*args, **kwargs):\n",
        "  del args, kwargs\n",
        "  streamer.reset()\n",
        "\n",
        "\n",
        "reset_button = ipw.Button(description=\"reset\")\n",
        "reset_button.on_click(_reset_state)\n",
        "\n",
        "# Hidden injection sliders.\n",
        "build_hidden_option_ui()\n",
        "\n",
        "LIVE_AUDIO_PROMPT, prompts = build_prompt_ui(\n",
        "    [\"lofi hip hop beat\",\n",
        "     \"funk jam\",\n",
        "     \"acid house\",\n",
        "    ],\n",
        "    num_audio_prompt=1,\n",
        ")\n",
        "\n",
        "# Building interactive UI\n",
        "ipd.display(\n",
        "    ipw.VBox([\n",
        "        widgets.area(\n",
        "            \"sampling options\",\n",
        "            *build_sampling_option_ui(),\n",
        "            reset_button,\n",
        "        ),\n",
        "        widgets.area(\n",
        "            \"prompts\",\n",
        "            *prompts,\n",
        "        ),\n",
        "    ])\n",
        ")\n",
        "\n",
        "streamer.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCXoLFXV83Po"
      },
      "source": [
        "# Step 3: â¬‡ï¸ Download your session\n",
        "\n",
        "Run the cells below to replay or download your input and the model output (as left and right channels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mapmcT6_AuEP"
      },
      "outputs": [],
      "source": [
        "# @title Align saved input and output\n",
        "\n",
        "context_seconds = streamer.system.config.context_length\n",
        "context_samples = int(\n",
        "    context_seconds * streamer.system.config.codec_sample_rate)\n",
        "\n",
        "all_inputs = streamer.injection_state.all_inputs[context_samples:]\n",
        "all_outputs = streamer.injection_state.all_outputs[context_samples:]\n",
        "\n",
        "delay_samples = int(streamer.system.config.crossfade_length * SAMPLE_RATE)\n",
        "if not use_prerecorded_input:\n",
        "  delay_samples += latency_samples\n",
        "delayed_inputs = np.concat(\n",
        "    [all_inputs[delay_samples:],\n",
        "     np.zeros_like(all_inputs[:delay_samples])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "l2yOL56Wxmng"
      },
      "outputs": [],
      "source": [
        "# @title Input audio\n",
        "print(\"\\n\")\n",
        "if use_prerecorded_input:\n",
        "  ipd.display(ipd.Audio(delayed_inputs.T, rate=SAMPLE_RATE))\n",
        "else:\n",
        "  ipd.display(ipd.Audio(delayed_inputs, rate=SAMPLE_RATE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mLi39BQ6w4TR"
      },
      "outputs": [],
      "source": [
        "# @title Output left\n",
        "print(\"\\n\")\n",
        "ipd.display(ipd.Audio(all_outputs[:, 0].T, rate=SAMPLE_RATE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iQ7K9WXvxDoQ"
      },
      "outputs": [],
      "source": [
        "# @title Output right\n",
        "print(\"\\n\")\n",
        "ipd.display(ipd.Audio(all_outputs[:, 1].T, rate=SAMPLE_RATE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmvBk8UOphdL"
      },
      "source": [
        "# License and terms\n",
        "\n",
        "Magenta RealTime is offered under a combination of licenses: the codebase is\n",
        "licensed under\n",
        "[Apache 2.0](https://github.com/magenta/magenta-realtime/blob/main/LICENSE), and\n",
        "the model weights under\n",
        "[Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/legalcode).\n",
        "\n",
        "In addition, we specify the following usage terms:\n",
        "\n",
        "Copyright 2025 Google LLC\n",
        "\n",
        "Use these materials responsibly and do not generate content, including outputs,\n",
        "that infringe or violate the rights of others, including rights in copyrighted\n",
        "content.\n",
        "\n",
        "Google claims no rights in outputs you generate using Magenta RealTime. You and\n",
        "your users are solely responsible for outputs and their subsequent uses.\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, all software and\n",
        "materials distributed here under the Apache 2.0 or CC-BY licenses are\n",
        "distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n",
        "either express or implied. See the licenses for the specific language governing\n",
        "permissions and limitations under those licenses. You are solely responsible for\n",
        "determining the appropriateness of using, reproducing, modifying, performing,\n",
        "displaying or distributing the software and materials, and any outputs, and\n",
        "assume any and all risks associated with your use or distribution of any of the\n",
        "software and materials, and any outputs, and your exercise of rights and\n",
        "permissions under the licenses."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}